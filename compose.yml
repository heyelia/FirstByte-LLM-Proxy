name: openai-performance-tester

services:

  openai_go_hedged_proxy:
    container_name: openai-go-proxy
    build:
      context: ./proxy
      dockerfile: ./Dockerfile
    restart: always
    ports:
      - "8080:8080"
    env_file:
      - ./proxy/.env
    environment:
      PORT: "8080"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/hc"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
